{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "var csv = require('csv-parser');  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "var fs = require('fs');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "var csv_train_file_path = './data/train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CsvParser {\n",
       "  _readableState:\n",
       "   ReadableState {\n",
       "     objectMode: true,\n",
       "     highWaterMark: 16,\n",
       "     buffer: BufferList { head: null, tail: null, length: 0 },\n",
       "     length: 0,\n",
       "     pipes: null,\n",
       "     pipesCount: 0,\n",
       "     flowing: true,\n",
       "     ended: false,\n",
       "     endEmitted: false,\n",
       "     reading: false,\n",
       "     sync: false,\n",
       "     needReadable: false,\n",
       "     emittedReadable: false,\n",
       "     readableListening: false,\n",
       "     resumeScheduled: true,\n",
       "     paused: false,\n",
       "     emitClose: true,\n",
       "     autoDestroy: false,\n",
       "     destroyed: false,\n",
       "     defaultEncoding: 'utf8',\n",
       "     awaitDrain: 0,\n",
       "     readingMore: false,\n",
       "     decoder: null,\n",
       "     encoding: null },\n",
       "  readable: true,\n",
       "  _events:\n",
       "   [Object: null prototype] {\n",
       "     prefinish: [Function: prefinish],\n",
       "     unpipe: [Function: onunpipe],\n",
       "     drain: [Function: pipeOnDrainFunctionResult],\n",
       "     error: [Function: onerror],\n",
       "     close:\n",
       "      { [Function: bound onceWrapper] listener: [Function: onclose] },\n",
       "     finish:\n",
       "      { [Function: bound onceWrapper] listener: [Function: onfinish] },\n",
       "     data: [Function],\n",
       "     end: [Function] },\n",
       "  _eventsCount: 8,\n",
       "  _maxListeners: undefined,\n",
       "  _writableState:\n",
       "   WritableState {\n",
       "     objectMode: true,\n",
       "     highWaterMark: 16,\n",
       "     finalCalled: false,\n",
       "     needDrain: false,\n",
       "     ending: false,\n",
       "     ended: false,\n",
       "     finished: false,\n",
       "     destroyed: false,\n",
       "     decodeStrings: true,\n",
       "     defaultEncoding: 'utf8',\n",
       "     length: 0,\n",
       "     writing: false,\n",
       "     corked: 0,\n",
       "     sync: true,\n",
       "     bufferProcessing: false,\n",
       "     onwrite: [Function: bound onwrite],\n",
       "     writecb: null,\n",
       "     writelen: 0,\n",
       "     bufferedRequest: null,\n",
       "     lastBufferedRequest: null,\n",
       "     pendingcb: 0,\n",
       "     prefinished: false,\n",
       "     errorEmitted: false,\n",
       "     emitClose: true,\n",
       "     autoDestroy: false,\n",
       "     bufferedRequestCount: 0,\n",
       "     corkedRequestsFree:\n",
       "      { next: null,\n",
       "        entry: null,\n",
       "        finish: [Function: bound onCorkedFinish] } },\n",
       "  writable: true,\n",
       "  allowHalfOpen: true,\n",
       "  _transformState:\n",
       "   { afterTransform: [Function: bound afterTransform],\n",
       "     needTransform: false,\n",
       "     transforming: false,\n",
       "     writecb: null,\n",
       "     writechunk: null,\n",
       "     writeencoding: null },\n",
       "  customNewline: false,\n",
       "  escape: 34,\n",
       "  headers: null,\n",
       "  mapHeaders: [Function: mapHeaders],\n",
       "  mapValues: [Function: mapValues],\n",
       "  newline: 10,\n",
       "  quote: 34,\n",
       "  raw: false,\n",
       "  separator: 44,\n",
       "  skipComments: false,\n",
       "  skipLines: null,\n",
       "  maxRowBytes: 9007199254740991,\n",
       "  strict: false,\n",
       "  _prev: null,\n",
       "  _prevEnd: 0,\n",
       "  _first: true,\n",
       "  _quoted: false,\n",
       "  _escaped: false,\n",
       "  _empty: '',\n",
       "  _Row: null,\n",
       "  _currentRowBytes: 0,\n",
       "  _line: 0 }"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file successfully processed\n"
     ]
    }
   ],
   "source": [
    "// var X = []\n",
    "var toxic_y = []\n",
    "var severe_toxic_y = []\n",
    "\n",
    "fs.createReadStream(csv_train_file_path)  \n",
    "  .pipe(csv())\n",
    "  .on('data', (row) => {\n",
    "    X.push(row.comment_text);\n",
    "    toxic_y.push(row.toxic)\n",
    "    severe_toxic_y.push(row.severe_toxic)\n",
    "  })\n",
    "  .on('end', () => {\n",
    "    console.log('CSV file successfully processed');\n",
    "  });"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file successfully processed\n"
     ]
    }
   ],
   "source": [
    "// var nlp = require('compromise') // TODO normalize text strings if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159571"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var toxic_labels = toxic_y.map(Number);\n",
    "var severe_toxic_labels = severe_toxic_y.map(Number);\n",
    "\n",
    "var labels = [];\n",
    "for(var i = 0; i , i < toxic_y.length; i++) {\n",
    "    if(toxic_labels[i] == 1 || severe_toxic_labels[i] == 1) {\n",
    "        labels.push(1);\n",
    "    } else {\n",
    "        labels.push(0);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "// TODO try normalize if needed, skip now\n",
    "\n",
    "// function preprocess(text) {\n",
    "//    return nlp(text).normalize({case:false, puctuation:false, plurals:true, parentheses:true, possessives:true, honorifics:true, verbs:true}).out('text');\n",
    "// }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "// var X_preprocessed = X.map(preprocess);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "// fs.writeFileSync('./data/X_preprocessed.json', JSON.stringify(X_preprocessed) , 'utf-8'); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "var X = JSON.parse(fs.readFileSync('./data/X_preprocessed.json'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.length == labels.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "function cleanString(input) {\n",
    "    var output = \"\";\n",
    "    for (var i=0; i<input.length; i++) {\n",
    "        if (input.charCodeAt(i) <= 127) {\n",
    "            output += input.charAt(i);\n",
    "        }\n",
    "    }\n",
    "    return output;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "var X_c = X.map(cleanString);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Function]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "String.prototype.isEmpty = function() {\n",
    "    return (this.length === 0 || !this.trim());\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "var removal_indices = []\n",
    "var X = X.filter(function(text, i) {\n",
    "    var empty = text.isEmpty();\n",
    "    if (empty == true){\n",
    "        removal_indices.push(i);\n",
    "    }\n",
    "    return !empty;\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "removal_indices.reverse().forEach(function(i) {\n",
    "    labels.splice(i, 1);\n",
    "    X_c.splice(i, 1);\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " labels.length == X.length && X.length == X_c.length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag-of-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143807"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var toxic_texsts = [];\n",
    "var non_toxic_texsts = [];\n",
    "for(var i = 0; i < labels.length; i++) {\n",
    "    if (labels[i] == 1) {\n",
    "        toxic_texsts.push(X_c[i]);\n",
    "    } else {\n",
    "        non_toxic_texsts.push(X_c[i]);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "var toxic_texsts = toxic_texsts.join(' ');\n",
    "var non_toxic_texsts = non_toxic_texsts.join(' ');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "// taken and modified from https://github.com/techfort/mimir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "function nGram(n) {\n",
    "  if (typeof n !== 'number' || isNaN(n) || n < 1 || n === Infinity) {\n",
    "    throw new Error('`' + n + '` is not a valid argument for n-gram')\n",
    "  }\n",
    "\n",
    "  return grams\n",
    "\n",
    "  // Create n-grams from a given value.\n",
    "  function grams(value) {\n",
    "    var nGrams = []\n",
    "    var index\n",
    "\n",
    "    if (value === null || value === undefined) {\n",
    "      return nGrams\n",
    "    }\n",
    "\n",
    "    value = value.slice ? value : String(value)\n",
    "    index = value.length - n + 1\n",
    "\n",
    "    if (index < 1) {\n",
    "      return nGrams\n",
    "    }\n",
    "\n",
    "    while (index--) {\n",
    "      nGrams[index] = value.slice(index, index + n)\n",
    "    }\n",
    "\n",
    "    return nGrams\n",
    "  }\n",
    "}\n",
    "\n",
    "function extractDictionary(textArray, f) {\n",
    "    var dict = {},\n",
    "      keys = [],\n",
    "      words;\n",
    "    \n",
    "    textArray = Array.isArray(textArray) ? textArray : [textArray];\n",
    "    textArray.forEach(function (text) {\n",
    "      words = f(text);\n",
    "      words.forEach(function (word) {\n",
    "        word = word.toLowerCase();\n",
    "        if (!dict[word] && word !== '') {\n",
    "          dict[word] = 1;\n",
    "          keys.push(word);\n",
    "        } else {\n",
    "          dict[word] += 1;\n",
    "        }\n",
    "      });\n",
    "    });\n",
    "\n",
    "    return {\n",
    "      words: keys,\n",
    "      dict: dict\n",
    "    };\n",
    "  }\n",
    "\n",
    "  function bow(text, vocabulary, f) {\n",
    "    var dict = extractDictionary([text], f).dict,\n",
    "      vector = [];\n",
    "\n",
    "    vocabulary.words.forEach(function (word) {\n",
    "      vector.push(dict[word] || 0);\n",
    "    });\n",
    "    return vector;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "function tokenize(text) {\n",
    "    return text\n",
    "      .replace(/'/g, '')\n",
    "      .replace(/[^A-Za-zА-Яа-яçÇğĞıİöÖşŞüÜ0-9_]/g, ' ')\n",
    "      .replace(/\\s\\s+/g, ' ')\n",
    "      .split(' ').map(function (s) {\n",
    "        return s.toLowerCase();\n",
    "      });\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "var voc_tox = extractDictionary(toxic_texsts, tokenize);   // voc = extractDictionary(X);\n",
    "var voc_non_tox = extractDictionary(non_toxic_texsts, tokenize);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "function sortProperties(obj)\n",
    "{\n",
    "  // convert object into array\n",
    "\tvar sortable=[];\n",
    "\tfor(var key in obj)\n",
    "\t\tif(obj.hasOwnProperty(key))\n",
    "\t\t\tsortable.push([key, obj[key]]); // each item is an array in format [key, value]\n",
    "\t\n",
    "\t// sort items by value\n",
    "\tsortable.sort(function(a, b)\n",
    "\t{\n",
    "\t  return b[1]-a[1]; // compare numbers\n",
    "\t});\n",
    "\treturn sortable; // array in format [ [ key1, val1 ], [ key2, val2 ], ... ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "var frequent_toxic_words = sortProperties(voc_tox['dict']).map(function(p) {return p[0]});\n",
    "//var frequent_non_toxic_words = sortProperties(voc_non_tox['dict']).map(function(p) {return p[0]});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "var half_length = Math.ceil(frequent_toxic_words.length / 3);    \n",
    "var frequent_toxic_words = frequent_toxic_words.splice(0,half_length);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "var voc = extractDictionary(frequent_toxic_words.join(' '), nGram(2));   // voc = extractDictionary(X);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "function remove_unfrequent(min, max, voc) {\n",
    "    words = [];\n",
    "    dict = voc['dict'];\n",
    "\n",
    "    for (var k in dict) {\n",
    "        value = dict[k];\n",
    "        if(value < min || value > max) {\n",
    "            delete dict[k];\n",
    "        } else {\n",
    "            words.push(k);\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    voc.words = words;\n",
    "    voc.dict = dict;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_unfrequent(5, 20000, voc);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.length == X.length && X_c.length == labels.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "function vectorize(text_original, voc) {\n",
    "    var text = cleanString(text_original).toLowerCase();\n",
    "    var vector = bow(text, voc, nGram(2))\n",
    "    return vector;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159093"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var vectors = [];\n",
    "for(var i = 0; i < X.length; i++) {\n",
    "    var vector = vectorize(X[i], voc);\n",
    "    vectors.push(vector);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_c.length == labels.length && labels.length == X.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the dataset out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs.writeFileSync('./data/y.json', JSON.stringify(labels) , 'utf-8'); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs.writeFileSync('./data/X.json', JSON.stringify(vectors) , 'utf-8'); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO Feature engineering, kitchen sink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "// TODO:\n",
    "// try normalize if needed, skip now\n",
    "// kitchen sink approach with feature engineering not just bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Javascript (Node.js)",
   "language": "javascript",
   "name": "javascript"
  },
  "language_info": {
   "file_extension": ".js",
   "mimetype": "application/javascript",
   "name": "javascript",
   "version": "11.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
