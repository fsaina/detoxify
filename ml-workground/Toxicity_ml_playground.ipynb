{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "var csv = require('csv-parser');  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "var fs = require('fs');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "var csv_train_file_path = './data/train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CsvParser {\n",
       "  _readableState:\n",
       "   ReadableState {\n",
       "     objectMode: true,\n",
       "     highWaterMark: 16,\n",
       "     buffer: BufferList { head: null, tail: null, length: 0 },\n",
       "     length: 0,\n",
       "     pipes: null,\n",
       "     pipesCount: 0,\n",
       "     flowing: true,\n",
       "     ended: false,\n",
       "     endEmitted: false,\n",
       "     reading: false,\n",
       "     sync: false,\n",
       "     needReadable: false,\n",
       "     emittedReadable: false,\n",
       "     readableListening: false,\n",
       "     resumeScheduled: true,\n",
       "     paused: false,\n",
       "     emitClose: true,\n",
       "     autoDestroy: false,\n",
       "     destroyed: false,\n",
       "     defaultEncoding: 'utf8',\n",
       "     awaitDrain: 0,\n",
       "     readingMore: false,\n",
       "     decoder: null,\n",
       "     encoding: null },\n",
       "  readable: true,\n",
       "  _events:\n",
       "   [Object: null prototype] {\n",
       "     prefinish: [Function: prefinish],\n",
       "     unpipe: [Function: onunpipe],\n",
       "     drain: [Function: pipeOnDrainFunctionResult],\n",
       "     error: [Function: onerror],\n",
       "     close:\n",
       "      { [Function: bound onceWrapper] listener: [Function: onclose] },\n",
       "     finish:\n",
       "      { [Function: bound onceWrapper] listener: [Function: onfinish] },\n",
       "     data: [Function],\n",
       "     end: [Function] },\n",
       "  _eventsCount: 8,\n",
       "  _maxListeners: undefined,\n",
       "  _writableState:\n",
       "   WritableState {\n",
       "     objectMode: true,\n",
       "     highWaterMark: 16,\n",
       "     finalCalled: false,\n",
       "     needDrain: false,\n",
       "     ending: false,\n",
       "     ended: false,\n",
       "     finished: false,\n",
       "     destroyed: false,\n",
       "     decodeStrings: true,\n",
       "     defaultEncoding: 'utf8',\n",
       "     length: 0,\n",
       "     writing: false,\n",
       "     corked: 0,\n",
       "     sync: true,\n",
       "     bufferProcessing: false,\n",
       "     onwrite: [Function: bound onwrite],\n",
       "     writecb: null,\n",
       "     writelen: 0,\n",
       "     bufferedRequest: null,\n",
       "     lastBufferedRequest: null,\n",
       "     pendingcb: 0,\n",
       "     prefinished: false,\n",
       "     errorEmitted: false,\n",
       "     emitClose: true,\n",
       "     autoDestroy: false,\n",
       "     bufferedRequestCount: 0,\n",
       "     corkedRequestsFree:\n",
       "      { next: null,\n",
       "        entry: null,\n",
       "        finish: [Function: bound onCorkedFinish] } },\n",
       "  writable: true,\n",
       "  allowHalfOpen: true,\n",
       "  _transformState:\n",
       "   { afterTransform: [Function: bound afterTransform],\n",
       "     needTransform: false,\n",
       "     transforming: false,\n",
       "     writecb: null,\n",
       "     writechunk: null,\n",
       "     writeencoding: null },\n",
       "  customNewline: false,\n",
       "  escape: 34,\n",
       "  headers: null,\n",
       "  mapHeaders: [Function: mapHeaders],\n",
       "  mapValues: [Function: mapValues],\n",
       "  newline: 10,\n",
       "  quote: 34,\n",
       "  raw: false,\n",
       "  separator: 44,\n",
       "  skipComments: false,\n",
       "  skipLines: null,\n",
       "  maxRowBytes: 9007199254740991,\n",
       "  strict: false,\n",
       "  _prev: null,\n",
       "  _prevEnd: 0,\n",
       "  _first: true,\n",
       "  _quoted: false,\n",
       "  _escaped: false,\n",
       "  _empty: '',\n",
       "  _Row: null,\n",
       "  _currentRowBytes: 0,\n",
       "  _line: 0 }"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file successfully processed\n"
     ]
    }
   ],
   "source": [
    "var X = []\n",
    "var toxic_y = []\n",
    "var severe_toxic_y = []\n",
    "\n",
    "fs.createReadStream(csv_train_file_path)  \n",
    "  .pipe(csv())\n",
    "  .on('data', (row) => {\n",
    "    X.push(row.comment_text);\n",
    "    toxic_y.push(row.toxic)\n",
    "    severe_toxic_y.push(row.severe_toxic)\n",
    "  })\n",
    "  .on('end', () => {\n",
    "    console.log('CSV file successfully processed');\n",
    "  });"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "// var nlp = require('compromise') // TODO normalize text strings if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "// TODO try normalize if needed, skip now\n",
    "\n",
    "// function preprocess(text) {\n",
    "//    return nlp(text).normalize({case:false, puctuation:false, plurals:true, parentheses:true, possessives:true, honorifics:true, verbs:true}).out('text');\n",
    "// }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "// var X_preprocessed = X.map(preprocess);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "// fs.writeFileSync('./data/X_preprocessed.json', JSON.stringify(X_preprocessed) , 'utf-8'); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "// var X = JSON.parse(fs.readFileSync('./data/X_preprocessed.json'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag-of-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "// taken and modified from https://github.com/techfort/mimir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "function nGram(n) {\n",
    "  if (typeof n !== 'number' || isNaN(n) || n < 1 || n === Infinity) {\n",
    "    throw new Error('`' + n + '` is not a valid argument for n-gram')\n",
    "  }\n",
    "\n",
    "  return grams\n",
    "\n",
    "  // Create n-grams from a given value.\n",
    "  function grams(value) {\n",
    "    var nGrams = []\n",
    "    var index\n",
    "\n",
    "    if (value === null || value === undefined) {\n",
    "      return nGrams\n",
    "    }\n",
    "\n",
    "    value = value.slice ? value : String(value)\n",
    "    index = value.length - n + 1\n",
    "\n",
    "    if (index < 1) {\n",
    "      return nGrams\n",
    "    }\n",
    "\n",
    "    while (index--) {\n",
    "      nGrams[index] = value.slice(index, index + n)\n",
    "    }\n",
    "\n",
    "    return nGrams\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "// nGram(2)('hello there how are you')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "function tokenize(text) {\n",
    "    return nGram(2)(text);\n",
    "}\n",
    "\n",
    "function extractDictionary(textArray) {\n",
    "    var dict = {},\n",
    "      keys = [],\n",
    "      words;\n",
    "    textArray = Array.isArray(textArray) ? textArray : [textArray];\n",
    "    textArray.forEach(function (text) {\n",
    "      words = tokenize(text);\n",
    "      words.forEach(function (word) {\n",
    "        word = word.toLowerCase();\n",
    "        if (!dict[word] && word !== '') {\n",
    "          dict[word] = 1;\n",
    "          keys.push(word);\n",
    "        } else {\n",
    "          dict[word] += 1;\n",
    "        }\n",
    "      });\n",
    "    });\n",
    "\n",
    "    return {\n",
    "      words: keys,\n",
    "      dict: dict\n",
    "    };\n",
    "  }\n",
    "\n",
    "function bow(text, vocabulary) {\n",
    "    var dict = extractDictionary([text]).dict,\n",
    "      vector = [];\n",
    "\n",
    "    vocabulary.words.forEach(function (word) {\n",
    "      vector.push(dict[word] || 0);\n",
    "    });\n",
    "    return vector;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "// stack overflow\n",
    "function cleanString(input) {\n",
    "    var output = \"\";\n",
    "    for (var i=0; i<input.length; i++) {\n",
    "        if (input.charCodeAt(i) <= 127) {\n",
    "            output += input.charAt(i);\n",
    "        }\n",
    "    }\n",
    "    return output;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "var X = X.map(cleanString);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Function]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "String.prototype.isEmpty = function() {\n",
    "    return (this.length === 0 || !this.trim());\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "var vocabulary = extractDictionary(X);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "function vectorize(text) {\n",
    "    return bow(text, vocabulary);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "var X_v = X.map(vectorize);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_v.length == toxic_y.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "var cutout = X_v.length - 1000;\n",
    "var X_test = X_v.slice(0, cutout);\n",
    "var y_test = severe_toxic_y.slice(0, cutout);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs.writeFileSync('./data/y.json', JSON.stringify(y_test) , 'utf-8'); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs.writeFileSync('./data/X.json', JSON.stringify(X_test) , 'utf-8'); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO Feature engineering, kitchen sink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "// TODO:\n",
    "// try normalize if needed, skip now\n",
    "// kitchen sink approach with feature engineering not just bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Javascript (Node.js)",
   "language": "javascript",
   "name": "javascript"
  },
  "language_info": {
   "file_extension": ".js",
   "mimetype": "application/javascript",
   "name": "javascript",
   "version": "11.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
